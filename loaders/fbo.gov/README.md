# Importing FedBizOpps data into FBOpen using the fbo.gov loader

## Limitations
* The fbo.gov loader currently loads only **COMBINE**, **PRESOL** and **MOD** opportunity notices.
* **MOD handling is limited.** Current behavior is to fully update the existing record with a MOD, while appending the new description to the old.
* The attachment crawler/loader is still very primitive. It works for attachments uploaded to fbo.gov or to which the listing's synopsis links directly. Attachments that are more than one hop removed from the listing page are *not* retrieved, but we hope to improve the crawler to do this.

## To do
* load AWARD and other notices types
* survey FBO listing archetypes to determine the algorithms for retrieving the relevant attachments for various types of notices, and implement that logic in the crawler/loader
* better failure handling for the metadata loader, attachment crawler, and attachment loader

## To install the loader
* Install Elasticsearch. On OS X, this is as easy as `brew install elasticsearch`.
* Install the attachment mapper plugin. See directions here: https://github.com/elasticsearch/elasticsearch-mapper-attachments 
* Restart Elasticsearch
* Create an index on your Elasticsearch cluster with the proper field mappings and settings (relative path to mapping given from the FBOpen root):
    * `curl -XPUT localhost:9200/fbopen --data-binary @elasticsearch/init.json`
* In the loaders/fbo.gov/ directory:
	* `sudo npm install`
        * (note: `sudo` is required so that the json package can be installed globally.)
* In the loaders/common/ directory:
    * `npm install`

## To import FedBizOpps data
After install, first load a full set of data using the one-time/weekly loader. Then you can simply run nightly updates.

### 1. One-time/Weekly full load
1. **`fbo-weekly.sh`**

	Downloads the full, weekly FBO XML file from ftp://ftp.fbo.gov.
	From the fbo.gov weekly XML data dump, creates and loads a set of Elasticsearch bulk load files.
    Finally, it visits each listing, scrapes the attachment URLs, downloads the attachment files, and loads them into Elasticsearch as child records.
	
    Required ENV vars:
    
    `$FBOPEN_ROOT` = the absolute path to your fbopen checkout

	Optional ENV vars:
	
	`$FBO_WEEKLY_XML_FILE` = where to save the downloaded file; default = *./workfiles/FBOFullXML.xml*
	`$FBOPEN_URI` = the URI of your Elasticsearch instance; default = *localhost:9200*
	`$FBOPEN_INDEX` = the name of the ES index to load into; default = *fbopen*
	
	Optional arguments:

 	`$1` = output filepath/name of the list of links to the FBO listings that were prepped; default = *./workfiles/listings-links.txt*

 	`$2` = directory into which attachments should be downloaded; default = *./fbo-attachments*


4. **`process-listing-links.sh < workfiles/listings-links.txt`** *(or alternate filename of list of links generated by step 2)*

	Downloads and loads into Solr the relevant attachments from each URL in the input stream. Assumes those URLs are fbo.gov listing pages.
	
	**NOTE 1:** This process is currently very slow, as it's completely synchronous. This is intentional; trying to download too many files at once, and trying to load too many into Solr at once, led to problems. Better would be (1) a throttled async version that handles several file downloads simultaneously, and (2) Do the Solr ingestion in a completely separate step.
	
	**NOTE 2:** It's also very buggy. There are many files that shouldn't be downloaded but are, and there are many files that are behind multiple clicks and/or unreachable without login. The algorithm for doing these downloads will have to improve significantly.
	
### Nightly updates
All at once: **`fbo-nightly.sh [YYYYMMDD]`** (defaults to yesterday)

	Downloads the nightly FBO XML file from ftp://ftp.fbo.gov.
	From the fbo.gov nightly XML data dump, creates and loads a set of Elasticsearch bulk load files.
    Finally, it visits each listing, scrapes the attachment URLs, downloads the attachment files, and loads them into Elasticsearch as child records.

    Required ENV vars:
    
    `$FBOPEN_ROOT` = the absolute path to your fbopen checkout

	Optional ENV vars:
	
	`$FBOPEN_URI` = the URI of your Elasticsearch instance; default = *localhost:9200*
	`$FBOPEN_INDEX` = the name of the ES index to load into; default = *fbopen*
	
If you want to do it in steps, consult `fbo-nightly.sh` for the proper commands.

The parser in the nightly code -- that is, the hard part -- is mostly the work of our predecessor [Adam Becker's](https://github.com/adamjacobbecker/) [fbo-parser](https://github.com/presidential-innovation-fellows/fbo-parser). Thanks Adam!
